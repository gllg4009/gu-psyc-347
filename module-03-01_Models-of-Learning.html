
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Models of Learning &#8212; Computational Models of Human Social Behavior (and Neuroscience)</title>
    
  <link rel="stylesheet" href="_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="RL Exercises" href="module-03-02_RL-Exercises.html" />
    <link rel="prev" title="Two-Armed Bandit" href="module-03-00_Two-Armed-Bandit.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />


<!-- Opengraph tags -->
<meta property="og:url"         content="https://shawnrhoads.github.io/gu-psyc-347/module-03-01_Models-of-Learning.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Models of Learning" />
<meta property="og:description" content="Models of Learning  This tutorial was inspired by and adapted from Wilson, R. C., &amp; Collins, A. G. (2019). Ten simple rules for the computational modeling of be" />
<meta property="og:image"       content="https://shawnrhoads.github.io/gu-psyc-347/_static/logo.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Computational Models of Human Social Behavior (and Neuroscience)</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Module 00
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-00_Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-01_Course-Schedule.html">
   Course Schedule
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-02_Course-Assignments.html">
   Course Assignments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-03_Reading-List.html">
   Reading List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-04_Getting-Started.html">
   Getting Started
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-00-05_Final-Projects.html">
   Final Project Guidelines
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 01
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-00_Jupyter-Notebooks.html">
   Jupyter Notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-01_Intro-to-Python.html">
   Intro to Python Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-02_Working-with-Data.html">
   Working with Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-01-03_Python-Exercises.html">
   Python Exercises
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 02
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-00_Linear-Modeling.html">
   Linear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-01_Nonlinear-Modeling.html">
   Nonlinear Modeling
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-02-02_Modeling-Exercises.html">
   Modeling Exercises
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Module 03
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-00_Two-Armed-Bandit.html">
   Two-Armed Bandit
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Models of Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="module-03-02_RL-Exercises.html">
   RL Exercises
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/module-03-01_Models-of-Learning.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/shawnrhoads/gu-psyc-347"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/shawnrhoads/gu-psyc-347/issues/new?title=Issue%20on%20page%20%2Fmodule-03-01_Models-of-Learning.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/shawnrhoads/gu-psyc-347/edit/master/module-03-01_Models-of-Learning.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulating-learning">
   Simulating Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-responding">
   Random Responding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#noisy-win-stay-lose-shift">
   Noisy Win-Stay-Lose-Shift
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#taking-the-average">
   Taking the Average?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rescorla-wagner">
   Rescorla-Wagner
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-parameters">
   Model Parameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-fitting">
   Model fitting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#computing-the-negative-loglikelihood">
     Computing the negative loglikelihood
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#brute-force">
       Brute Force
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-descent">
       Gradient Descent
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-recovery">
     Parameter Recovery
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a class="reference external" href="https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-03-01_Models-of-Learning.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="section" id="models-of-learning">
<h1>Models of Learning<a class="headerlink" href="#models-of-learning" title="Permalink to this headline">¶</a></h1>
<p>This tutorial was inspired by and adapted from <a class="reference external" href="https://elifesciences.org/articles/49547">Wilson, R. C., &amp; Collins, A. G. (2019). Ten simple rules for the computational modeling of behavioral data. eLife.</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span> <span class="c1"># finding optimal params in models</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>             <span class="c1"># statistical tools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                  <span class="c1"># matrix/array functions</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>                 <span class="c1"># loading and manipulating data</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>        <span class="c1"># interactive display</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>     <span class="c1"># plotting</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>                <span class="c1"># set seed for reproducibility</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="simulating-learning">
<h2>Simulating Learning<a class="headerlink" href="#simulating-learning" title="Permalink to this headline">¶</a></h2>
<p>Recall the example from our reading <a class="reference external" href="https://elifesciences.org/articles/49547">Wilson &amp; Collins (2019)</a>: participants make a series of <span class="math notranslate nohighlight">\(T\)</span> choices between <span class="math notranslate nohighlight">\(K\)</span> slot machines (multi-armed bandits) with the goal of maximizing their earnings. If played on trial <span class="math notranslate nohighlight">\(t\)</span>, each slot machine, <span class="math notranslate nohighlight">\(k\)</span>, pays out a reward, <span class="math notranslate nohighlight">\(r_t\)</span>, which is <code class="docutils literal notranslate"><span class="pre">1</span></code> with reward probability, <span class="math notranslate nohighlight">\(\mu^k_t\)</span>, and otherwise <code class="docutils literal notranslate"><span class="pre">0</span></code>. The reward probabilities are different for each slot machine and are initially unknown to the participant. In the simplest version of the task, the reward probabilities are fixed over time.</p>
<p>We have three experimental parameters for this task:</p>
<ol class="simple">
<li><p>the number of trials, <span class="math notranslate nohighlight">\(T\)</span></p></li>
<li><p>the number of slot machines, <span class="math notranslate nohighlight">\(K\)</span></p></li>
<li><p>the reward probabilities of the different options, <span class="math notranslate nohighlight">\(\mu^k_t\)</span>, which may or may not change over time</p></li>
</ol>
<p>Let’s try out the different models proposed in the paper and simulate some behavior based on these models. We will set <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">=</span> <span class="pre">100</span></code> (100 trials), <code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">2</span></code> (two slot machines), and <code class="docutils literal notranslate"><span class="pre">mu</span> <span class="pre">=</span> <span class="pre">[.2,</span> <span class="pre">.8]</span></code> (machine 1 pays out with 20% probability, machine 2 pays out with 80% probability).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="random-responding">
<h2>Random Responding<a class="headerlink" href="#random-responding" title="Permalink to this headline">¶</a></h2>
<p>In the first model, participants are assumed to not engage with the task at all. They simply select machines at random with a possible bias for one machine over the other. This bias is captured with a parameter <span class="math notranslate nohighlight">\(b\)</span> (which is between 0 and 1) such that the probability of choosing the two options is</p>
<div class="math notranslate nohighlight">
\[
p^1_t = b \quad \mbox{and}\quad p^2_t = 1-b
\]</div>
<p>Thus, for two bandits, the random responding model has just one free parameter, controlling the overall bias for option 1 over option 2, <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p><em><strong>Note</strong></em>: This kind of random behavior is not uncommon in behavioral experiments, especially when participants have no incentives for performing well. Modeling such behavior can be important to identify these “checked-out” participants (either for exclusion or to study the “checked-out” behavior itself).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify the random responding model as a function</span>
<span class="k">def</span> <span class="nf">simulate_RandomModel</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>

        <span class="c1"># compute choice probabilities</span>
        <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">b</span><span class="p">]</span>

        <span class="c1"># make choice according to choice probababilities</span>
        <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

        <span class="c1"># generate reward based on choice</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
    
    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulate the random responding model</span>
<span class="n">c1</span><span class="p">,</span> <span class="n">r1</span> <span class="o">=</span> <span class="n">simulate_RandomModel</span><span class="p">(</span><span class="n">b</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the simulation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">r1</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c1</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Random Responding Behavior&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-03-01_Models-of-Learning_7_0.png" src="_images/module-03-01_Models-of-Learning_7_0.png" />
</div>
</div>
<p>As we can see, the behavior here is fairly random.</p>
</div>
<div class="section" id="noisy-win-stay-lose-shift">
<h2>Noisy Win-Stay-Lose-Shift<a class="headerlink" href="#noisy-win-stay-lose-shift" title="Permalink to this headline">¶</a></h2>
<p>The win-stay-lose-shift model is a simple model that assumes that participants adapt behavior according to feedback on the previous trial. The model repeats rewarded actions and switches away from unrewarded actions. In the noisy version of the model, the win-stay-lose-shift rule is applied probabilistically, such that the model applies the win-stay-lose-shift rule with probability <span class="math notranslate nohighlight">\(1-\epsilon\)</span>, and chooses randomly with probability <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>In the two-bandit case, the probability of choosing option <span class="math notranslate nohighlight">\(k\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
p^k_t = \left\{
        \begin{array}{cc}
             1- \epsilon / 2 
             &amp; \mbox{if } (c_{t-1} = k \mbox{ and } r_{t-1} = 1) \mbox{ OR } (c_{t-1} \ne k \mbox{ and } r_{t-1} = 0)\\
             \epsilon / 2 
             &amp; \mbox{if } (c_{t-1} \ne k \mbox{ and } r_{t-1} = 1) \mbox{ OR } (c_{t-1} = k \mbox{ and } r_{t-1} = 0)
        \end{array}
    \right.
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(c_t=1,2\)</span> is the choice at trial <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(r_t=0,1\)</span> the reward at trial <span class="math notranslate nohighlight">\(t\)</span>. This model also only has one free parameter, the overall level of randomness, <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_WSLS</span><span class="p">(</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    
    <span class="c1"># last reward/action (initialize as nan)</span>
    <span class="n">last_reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="n">last_choice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>

        <span class="c1"># compute choice probabilities</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">last_reward</span><span class="p">):</span>

            <span class="c1"># first trial choose randomly</span>
            <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>

            <span class="c1"># choice depends on last reward</span>
            <span class="k">if</span> <span class="n">last_reward</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>

                <span class="c1"># win stay (with probability 1-epsilon)</span>
                <span class="n">p</span> <span class="o">=</span> <span class="p">[(</span><span class="n">epsilon</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
                <span class="n">p</span><span class="p">[</span><span class="n">last_choice</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="o">/</span><span class="mi">2</span>
            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># lose shift (with probability 1-epsilon)</span>
                <span class="n">p</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epsilon</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
                <span class="n">p</span><span class="p">[</span><span class="n">last_choice</span><span class="p">]</span> <span class="o">=</span> <span class="n">epsilon</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
            
        <span class="c1"># make choice according to choice probababilities</span>
        <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">)),</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>

        <span class="c1"># generate reward based on choice</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>

        <span class="n">last_choice</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
        <span class="n">last_reward</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c2</span><span class="p">,</span> <span class="n">r2</span> <span class="o">=</span> <span class="n">simulate_WSLS</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the simulation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">r2</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c2</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Noisy Win-Stay-Lose-Shift Behavior&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/module-03-01_Models-of-Learning_12_0.png" src="_images/module-03-01_Models-of-Learning_12_0.png" />
</div>
</div>
<p>Here, we can see that behavior switches (with noise) whenever there is no reward on the previous trial.</p>
</div>
<div class="section" id="taking-the-average">
<h2>Taking the Average?<a class="headerlink" href="#taking-the-average" title="Permalink to this headline">¶</a></h2>
<p>As discussed previously in class, another very simple thing we could do is to compute the average reward (then choose probabilistically according to the updated value of the machines). This model can be expressed as:</p>
<div class="math notranslate nohighlight">
\[
V(t) = \frac{1}{T} \sum_{i=1}^{T} r_i
\]</div>
<p>However, we crucially learned that there’s a big conceptual problem with the model as it’s currently written. Even if humans or animals are computing the mean of the rewards it is unlikely they are doing it using this equation. Even with <code class="docutils literal notranslate"><span class="pre">T=50</span></code> trials, how easy do you think it would be to compute a sum like that directly? How about when <code class="docutils literal notranslate"><span class="pre">T=100</span></code>?</p>
<p>The problem is that we would have to keep track of all the rewards we’ve seen so far to compute it. For example, when <code class="docutils literal notranslate"><span class="pre">T=100</span></code> we have to keep track of 100 rewards. If <code class="docutils literal notranslate"><span class="pre">T=10000</span></code>, then we need to keep track of a 10,000 rewards! This doesn’t seem plausible. No one can remember a random string of a ten-thousand 0s and 1s (the world record for <a class="reference external" href="https://www.guinnessworldrecords.com/world-records/360573-most-binary-digits-memorised-in-30-minutes#:~:text=The%20most%20binary%20digits%20memorized,4%20to%208%20December%202019.">remembering binary digits in 30 minutes is 7,485</a>).</p>
<p>Maybe we can “take the average” in a different kind of way that doesn’t involve keeping track of so many outcomes!</p>
</div>
<div class="section" id="rescorla-wagner">
<h2>Rescorla-Wagner<a class="headerlink" href="#rescorla-wagner" title="Permalink to this headline">¶</a></h2>
<p>Enter <strong>Rescorla-Wagner</strong>. As discussed in class, Rescorla and Wagner (in one of great papers of the 20th Century) proposed that learning occurs when there is a prediction error. In their model, participants first learn the expected value of each slot machine based on the history of previous outcomes and then use these values to make a decision about what to do next. A simple model of learning is the Rescorla-Wagner learning rule (Rescorla &amp; Wagner, 1972) whereby the value of option <span class="math notranslate nohighlight">\(k\)</span>, <span class="math notranslate nohighlight">\(Q^k_t\)</span> is updated in response to reward <span class="math notranslate nohighlight">\(r_t\)</span> according to:</p>
<div class="math notranslate nohighlight">
\[
Q^k_{t+1} = Q^k_t + \alpha (r_t - Q^k_t)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate, which is bounded between 0 and 1 and captures the extent to which the prediction error, <span class="math notranslate nohighlight">\((r_t - Q^k_t)\)</span>, updates the value (i.e., a higher <span class="math notranslate nohighlight">\(\alpha\)</span> value will put greater weight on the prediction error). For simplicity, we assume that the initial value, <span class="math notranslate nohighlight">\(Q^k_0=0\)</span>, although it is possible to treat the <span class="math notranslate nohighlight">\(Q^k_0\)</span> as a free parameter of the model (this is also the intercept).</p>
<p>A simple model of decision making is to assume that participants use the options’ values to guide their decisions, choosing the most valuable option most frequently, but occasionally making ‘mistakes’ (or exploring) by choosing a low value option. One choice rule with these properties is known as the <strong>‘softmax’ choice rule</strong>, which chooses option <span class="math notranslate nohighlight">\(k\)</span> with probability:</p>
<div class="math notranslate nohighlight">
\[
p^k_t = \frac{\exp(\theta Q^k_t)}{\sum_{i=1}^K \exp(\theta Q^i_t)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> is the ‘inverse temperature’ parameter that controls the level of stochasticity in the choice, ranging from <span class="math notranslate nohighlight">\(\theta = 0\)</span> for completely random responding and <span class="math notranslate nohighlight">\(\theta = \infty\)</span> for deterministically choosing the highest value option.</p>
<p>Combining the learning and decision rules gives a simple model of decision making in this task with two free parameters: the learning rate, <span class="math notranslate nohighlight">\(\alpha\)</span>, and the inverse temperature <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">noisy_choice</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
    
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">int</span><span class="p">)</span>

    <span class="n">Q_stored</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>

        <span class="c1"># store values for Q_{t+1}</span>
        <span class="n">Q_stored</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">Q</span>
        
        <span class="c1"># compute choice probabilities</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">p0</span>
        
        <span class="c1"># make choice according to choice probababilities</span>
        <span class="c1"># as weighted coin flip to make a choice</span>
        <span class="c1"># choose stim 0 if random number is in the [0 p0] interval</span>
        <span class="c1"># and 1 otherwise</span>
        <span class="k">if</span> <span class="n">noisy_choice</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">p0</span><span class="p">:</span> 
                <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># make choice without noise</span>
            <span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">([</span><span class="n">p0</span><span class="p">,</span><span class="n">p1</span><span class="p">])</span>
        
        <span class="c1"># generate reward based on choice</span>
        <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">mu</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>

        <span class="c1"># update values</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>

    <span class="k">return</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q_stored</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the simulation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">r3</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c3</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">bbe70f49457b</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># plot the simulation</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">r3</span><span class="p">,</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c3</span><span class="p">,</span> <span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;outcome&#39;</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;r3&#39; is not defined
</pre></div>
</div>
</div>
</div>
<p>As we can observe, choices for the machine that yields less rewards become less frequent over trials.</p>
<p>We can also plot the values of the machines over trials. Let’s see what that looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the simulation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;80% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="s1">&#39;m-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;20% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c3</span><span class="p">,</span> <span class="s1">&#39;b+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>It’s pretty cool that the value of the machines over trials slowly converges towards their reward outcomes probabilities (20% and 80%)!</p>
<hr></div>
<div class="section" id="model-parameters">
<h2>Model Parameters<a class="headerlink" href="#model-parameters" title="Permalink to this headline">¶</a></h2>
<p>Before moving on, let’s get a better intuition for how learning changes for different values of the probability of the first machine, <span class="math notranslate nohighlight">\(\alpha\)</span>, and <span class="math notranslate nohighlight">\(\theta\)</span></p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_values</span><span class="p">(</span><span class="n">beta_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="n">beta_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">],</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">mu</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">% machine&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="s1">&#39;m-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">mu</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s1">.0f</span><span class="si">}</span><span class="s1">% machine&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">c</span><span class="p">,</span> <span class="s1">&#39;b+&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;choice&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span><span class="n">trials</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">200</span><span class="p">),</span>
                  <span class="n">probability</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="n">alpha_hat</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                  <span class="n">theta_hat</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">plot_interactive</span><span class="p">(</span><span class="n">trials</span><span class="p">,</span> <span class="n">probability</span><span class="p">,</span> <span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">):</span>
    <span class="n">plot_values</span><span class="p">(</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">trials</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="o">-</span><span class="n">probability</span><span class="p">,</span> <span class="n">probability</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<hr></div>
<div class="section" id="model-fitting">
<h2>Model fitting<a class="headerlink" href="#model-fitting" title="Permalink to this headline">¶</a></h2>
<p>A key component of computational modeling is estimating the values of the parameters that best describe your behavioral data. While there are a number of different ways of estimating parameters, we will focus on the <strong>Maximum-Likelihood</strong> approach. Mathematical details can be found in [Module 02] or in the Appendix of <a class="reference external" href="https://elifesciences.org/articles/49547">Wilson &amp; Collins (2019)</a>.</p>
<p>In the maximum likelihood approach to model fitting, our goal is to find the parameter values of a model <span class="math notranslate nohighlight">\(m\)</span> that maximize the <strong>likelihood of the data</strong> <span class="math notranslate nohighlight">\(d_{1:T}\)</span>. For example, in the Rescorla-Wagner case, we want to maximize the likelihood of the data <span class="math notranslate nohighlight">\(d_{1:T}\)</span> given parameter values <span class="math notranslate nohighlight">\((\alpha, \theta)_m\)</span> of the model <span class="math notranslate nohighlight">\(m\)</span>.</p>
<div class="section" id="computing-the-negative-loglikelihood">
<h3>Computing the negative loglikelihood<a class="headerlink" href="#computing-the-negative-loglikelihood" title="Permalink to this headline">¶</a></h3>
<p>Maximizing the likelihood is equivalent to maximizing the log of the likelihood, <span class="math notranslate nohighlight">\(\log \mathcal{L} = \log p( d_{1:t-1} | (\alpha, \theta)_m, m)\)</span>, which is numerically more tractable. A simple mathematical derivation shows that this loglikelihood can be written in terms of the choice probabilities of the individual model as</p>
<div class="math notranslate nohighlight">
\[
\log \mathcal{L} = \log p(d_{1:T} | (\alpha, \theta)_m, m) = \sum_{t=1}^T \log p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m)
\]</div>
<p>where <span class="math notranslate nohighlight">\(p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m)\)</span> is the <strong>probability of each individual choice</strong> given the parameters of the model and available information up to that choice.</p>
<p><em><strong>Recall that maximizing the loglikelihood is the same as minimizing the negative loglikelihood!</strong></em> Thus, we can rewrite the equation above as:</p>
<div class="math notranslate nohighlight">
\[
negative \log \mathcal{L} = -\sum_{t=1}^T \log p(c_t | d_{1:t-1}, s_t, (\alpha, \theta)_m, m)
\]</div>
<p>In practice, the likelihood is simply a function of the data and parameters that we can define for each of the models under consideration. In this notebook, we will focus on the Rescorla Wagner model. For this model, we can write a negative loglikelihood function as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">negll_RescorlaWagner</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span> <span class="o">=</span> <span class="n">params</span>
    
    <span class="n">Q</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
    <span class="n">T</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="n">choiceProb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">float</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        
        <span class="c1"># compute choice probabilities for k=2</span>
        <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">theta</span><span class="o">*</span><span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">p</span> <span class="o">=</span> <span class="p">[</span><span class="n">p0</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">p0</span><span class="p">]</span>

        <span class="c1"># compute choice probability for actual choice</span>
        <span class="n">choiceProb</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>

        <span class="c1"># update values</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="n">r</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">-</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span>
        <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">=</span> <span class="n">Q</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">t</span><span class="p">]]</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">delta</span>
        
    <span class="n">negLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">choiceProb</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">negLL</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulate choices from RW Model</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">c4</span><span class="p">,</span> <span class="n">r4</span><span class="p">,</span> <span class="n">Q2</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">T</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span><span class="o">.</span><span class="mi">8</span><span class="p">])</span>

<span class="c1"># evaluate negative log-likelihood for </span>
<span class="c1"># this simulated dataset at some other parameter values</span>
<span class="n">alpha_hat</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">theta_hat</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">negLL</span> <span class="o">=</span> <span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_hat</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">],</span> <span class="n">c4</span><span class="p">,</span> <span class="n">r4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="brute-force">
<h4>Brute Force<a class="headerlink" href="#brute-force" title="Permalink to this headline">¶</a></h4>
<p>In principle, finding the maximum likelihood parameters is as ‘simple’ as maximizing the loglikelihood. In practice, finding the maximum of a function is not a trivial process. As discussed in Module 02, the simplest approach would be a brute force search of the entire parameter space. Let’s try that for our simulated data set. For simplicity, let’s assume that we know <span class="math notranslate nohighlight">\(\theta\)</span> but don’t know <span class="math notranslate nohighlight">\(\alpha\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nLL</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">alpha_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="k">for</span> <span class="n">alpha_val</span> <span class="ow">in</span> <span class="n">alpha_vals</span><span class="p">:</span>
    <span class="n">nLL</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">negll_RescorlaWagner</span><span class="p">([</span><span class="n">alpha_val</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">c4</span><span class="p">,</span> <span class="n">r4</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_vals</span><span class="p">,</span> <span class="n">nLL</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_vals</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nLL</span><span class="p">)],</span> <span class="n">nLL</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">nLL</span><span class="p">)],</span> <span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;optimal $\hat \alpha$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;negative loglikelihood&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;learning rate, $\hat \alpha$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>By plotting, the relationship between negative loglikelihood and <span class="math notranslate nohighlight">\(\hat \alpha\)</span>, we can see that optimal <span class="math notranslate nohighlight">\(\hat \alpha\)</span> is at the lowest negative loglikelihood.</p>
</div>
<div class="section" id="gradient-descent">
<h4>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h4>
<p>As we know from Module 2, the brute force approach is unfeasible outside of the simplest cases (e.g. one or two parameters with tight bounds) due to the high computational costs of evaluating the likelihood function at a large number of points.</p>
<p>Fortunately, a number of tools exist for finding local maxima (and minima) of functions quickly using variations on gradient ascent (or descent), such as <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code>!</p>
<p>Let’s try it out!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># gradient descent to minimize neg LL</span>
<span class="n">res_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="c1"># set initial neg LL to be inf</span>

<span class="c1"># guess several different starting points for alpha</span>
<span class="k">for</span> <span class="n">alpha_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">theta_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
        
        <span class="c1"># guesses for alpha, theta will change on each loop</span>
        <span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_guess</span><span class="p">,</span> <span class="n">theta_guess</span><span class="p">)</span>
        
        <span class="c1"># minimize neg LL</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">negll_RescorlaWagner</span><span class="p">,</span> 
                          <span class="n">init_guess</span><span class="p">,</span> 
                          <span class="p">(</span><span class="n">c4</span><span class="p">,</span> <span class="n">r4</span><span class="p">),</span> 
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">50</span><span class="p">)))</span>
        
        <span class="c1"># if current negLL is smaller than the last negLL,</span>
        <span class="c1"># then store current data</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="n">res_nll</span><span class="p">:</span>
            <span class="n">res_nll</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
            <span class="n">param_fits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

<span class="c1"># also, compute BIC</span>
<span class="n">BIC</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">init_guess</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">c4</span><span class="p">))</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">res_nll</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;alpha_hat = </span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">, theta_hat = </span><span class="si">{</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">fr</span><span class="s1">&#39;BIC = </span><span class="si">{</span><span class="n">BIC</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="parameter-recovery">
<h3>Parameter Recovery<a class="headerlink" href="#parameter-recovery" title="Permalink to this headline">¶</a></h3>
<p>It is important to check whether the fitting procedure gives meaningful parameter values in the best case scenario (i.e., when fitting fake data where the ‘true’ parameter values are known). Such a procedure is known as <strong>parameter recovery</strong> and is a crucial part of any model-based analysis.</p>
<p>The recipe for parameter recovery is quite simple</p>
<ol class="simple">
<li><p>Simulate fake data with known parameter values</p></li>
<li><p>Fit the model to this fake data to try to ‘recover’ the parameters</p></li>
<li><p>Compare the recovered parameters to their true values</p></li>
</ol>
<p>In a perfect world, the simulated and recovered parameters will be tightly correlated without bias. If there is only a weak correlation between simulated and recovered parameters and/or a significant bias, then this is an indication that there is either a bug in your code (often the case) or the experiment is underpowered to assess this model (also often the case!).</p>
<p>Let’s simulate data for 100 ‘fake’ participants.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simulate subjects&#39; alpha and theta params</span>
<span class="n">alpha_sim</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">truncnorm</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="o">.</span><span class="mi">1</span><span class="p">),</span>
                                <span class="p">(</span><span class="mi">1</span><span class="o">-.</span><span class="mi">25</span><span class="p">),</span>
                                <span class="n">loc</span><span class="o">=.</span><span class="mi">25</span><span class="p">,</span>
                                <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>
<span class="n">theta_sim</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">truncnorm</span><span class="o">.</span><span class="n">rvs</span><span class="p">((</span><span class="mi">0</span><span class="o">-.</span><span class="mi">25</span><span class="p">),</span>
                                <span class="p">(</span><span class="mi">10</span><span class="o">-.</span><span class="mi">25</span><span class="p">),</span>
                                <span class="n">loc</span><span class="o">=</span><span class="mf">1.25</span><span class="p">,</span>
                                <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">))</span>

<span class="c1"># initialize lists to store params and data</span>
<span class="n">negll_sim</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Q_fit</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">alpha_fit</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">theta_fit</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># loop over subjects</span>
<span class="k">for</span> <span class="n">subj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">subj</span><span class="p">)</span>
    
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha_sim</span><span class="p">[</span><span class="n">subj</span><span class="p">]</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta_sim</span><span class="p">[</span><span class="n">subj</span><span class="p">]</span>
    
    <span class="c1"># simulate subject data based on alpha, theta</span>
    <span class="n">c_sim</span><span class="p">,</span> <span class="n">r_sim</span><span class="p">,</span> <span class="n">Q_sim</span> <span class="o">=</span> <span class="n">simulate_RescorlaWagner</span><span class="p">([</span><span class="n">alpha</span><span class="p">,</span> <span class="n">theta</span><span class="p">],</span> <span class="n">T</span><span class="p">,</span> <span class="n">mu</span><span class="p">);</span>
    
    <span class="c1"># gradient descent to minimize neg LL</span>
    <span class="n">res_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    
    <span class="c1"># guess several different starting points for alpha</span>
    <span class="k">for</span> <span class="n">alpha_guess</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
        
        <span class="c1"># guesses for alpha will change</span>
        <span class="c1"># guesses for theta will be constant</span>
        <span class="n">init_guess</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_guess</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
        
        <span class="c1"># minimize neg LL</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">negll_RescorlaWagner</span><span class="p">,</span> 
                          <span class="n">init_guess</span><span class="p">,</span> 
                          <span class="p">(</span><span class="n">c_sim</span><span class="p">,</span> <span class="n">r_sim</span><span class="p">),</span> 
                          <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">)))</span>
        
        <span class="c1"># if current negLL is smaller than the last negLL,</span>
        <span class="c1"># then store current data</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span> <span class="o">&lt;</span> <span class="n">res_nll</span><span class="p">:</span>
            <span class="n">res_nll</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">fun</span>
            <span class="n">param_fits</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
            <span class="n">Q_vals</span> <span class="o">=</span> <span class="n">Q_sim</span>
    
    <span class="c1"># append model fits to lists</span>
    <span class="n">negll_sim</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_nll</span><span class="p">)</span>
    <span class="n">Q_fit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Q_vals</span><span class="p">)</span>
    <span class="n">alpha_fit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">theta_fit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_fits</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot average stimulus values over trials </span>
<span class="n">Q_means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Q_fit</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># mean over subjects </span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q_means</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;80% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">Q_means</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="s1">&#39;m-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;20% machine&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;trials&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Rescorla-Wagner Learning&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># parameter recovery for alpha</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alpha_sim</span><span class="p">,</span> <span class="n">alpha_fit</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;fit $\alpha$&#39;</span><span class="p">,</span>
            <span class="n">xlabel</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;simulated $\alpha$&#39;</span><span class="p">,</span>
            <span class="n">title</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;Parameter Recovery for $\alpha$&#39;</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">theta_sim</span><span class="p">,</span> <span class="n">theta_fit</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">ylabel</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;fit $\theta$&#39;</span><span class="p">,</span>
            <span class="n">xlabel</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;simulated $\theta$&#39;</span><span class="p">,</span>
            <span class="n">title</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;Parameter Recovery for $\theta$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="module-03-00_Two-Armed-Bandit.html" title="previous page">Two-Armed Bandit</a>
    <a class='right-next' id="next-link" href="module-03-02_RL-Exercises.html" title="next page">RL Exercises</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Shawn A. Rhoads<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'G-KG3N20S55G', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>
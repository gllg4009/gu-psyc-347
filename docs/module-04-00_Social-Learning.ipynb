{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "periodic-carolina",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/shawnrhoads/gu-psyc-347/blob/master/docs/module-04-00_Social-Learning.ipynb)\n",
    "\n",
    "# Social Learning\n",
    "\n",
    "These exercises were inspired by and adapted from [Models of Learning](http://www.hannekedenouden.ruhosting.nl/RLtutorial/Instructions.html) by Jill O'Reilly and Hanneke den Ouden, [NSCS 344 - Modeling the Mind](http://u.arizona.edu/~bob/web_NSCS344/) by Robert C. Wilson, the [Neuromatch Academy tutorials](https://github.com/NeuromatchAcademy/course-content) [[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)], [Lockwood, et al. (2016). Neurocomputational mechanisms of prosocial learning and links to empathy. Proceedings of the National Academy of Sciences.](https://doi.org/10.1073/pnas.1603198113), and [Lengersdorff, et al. (2020). When implicit prosociality trumps selfishness: the neural valuation system underpins more optimal choices when learning to avoid harm to others than to oneself. Journal of Neuroscience.](https://www.jneurosci.org/content/40/38/7286)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-amount",
   "metadata": {},
   "source": [
    "In this module, we will explore how to apply reinforcement learning and decision-making models to behavior in social contexts. In this framework, individuals rely on **prediction errors** (the difference between the actual outcome and the expected outcome) from sampling different options or actions that yield either positive or negative outcomes. In this way, individuals learn **value associations** between actions/options and their outcomes.\n",
    "\n",
    "While the majority of studies examining reinforcement learning examine how individuals learn the association betwwen actions/options and outcomes that affect themselves alone, recent studies have begun to test how the this framework could be applied in social contexts (i.e., when people learn various associations *from others* (observational learning) ([]()) and *for others* (prosocial learning) ([Lockwood, et al., 2016](https://doi.org/10.1073/pnas.1603198113)); or when people learn *about others'* beliefs ([]()) or traits ([]()).\n",
    "\n",
    "We have read about these first two types of learning in social contexts for far (and will begin learning about the third soon). Now, we will examine a specific type and unpack how this learning might change across different contexts/situations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-morris",
   "metadata": {},
   "source": [
    "## Learning for others\n",
    "\n",
    "We will first review the model that best explained human behavior during a learning study, where individuals learned how their actions affected outcomes for **themselves**, a **stranger**, and **no one** ([Lockwood, et al., 2016](https://doi.org/10.1073/pnas.1603198113))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-telephone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-sister",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-meeting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-marina",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
